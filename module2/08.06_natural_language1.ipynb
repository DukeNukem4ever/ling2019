{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmtKEcXnO9LE"
   },
   "source": [
    "## 20 news groups\n",
    "Задача: определить по тексту поста, к какой теме (из 20 возможных) он относится "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wWnH_EiwO9dh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pUgrGWKjO9mG"
   },
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rGygtQ8cdKqW",
    "outputId": "11db6c7b-1b82-4a85-c54e-eeab2d070340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'filenames', 'target', 'target_names']"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# не знаем, что за объект возвраащет fetch_20newsgroups() и какие у него атрибуты\n",
    "# смотрим\n",
    "dir(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ms-B3tQndDCi",
    "outputId": "7548004d-d809-45b5-e7f8-36c0afda9518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
      "fetching / caching functions that downloads the data archive from\n",
      "the original `20 newsgroups website`_, extracts the archive contents\n",
      "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
      ":func:`sklearn.datasets.load_files` on either the training or\n",
      "testing set folder, or both of them::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_20newsgroups\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "\n",
      "  >>> from pprint import pprint\n",
      "  >>> pprint(list(newsgroups_train.target_names))\n",
      "  ['alt.atheism',\n",
      "   'comp.graphics',\n",
      "   'comp.os.ms-windows.misc',\n",
      "   'comp.sys.ibm.pc.hardware',\n",
      "   'comp.sys.mac.hardware',\n",
      "   'comp.windows.x',\n",
      "   'misc.forsale',\n",
      "   'rec.autos',\n",
      "   'rec.motorcycles',\n",
      "   'rec.sport.baseball',\n",
      "   'rec.sport.hockey',\n",
      "   'sci.crypt',\n",
      "   'sci.electronics',\n",
      "   'sci.med',\n",
      "   'sci.space',\n",
      "   'soc.religion.christian',\n",
      "   'talk.politics.guns',\n",
      "   'talk.politics.mideast',\n",
      "   'talk.politics.misc',\n",
      "   'talk.religion.misc']\n",
      "\n",
      "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
      "attribute is the integer index of the category::\n",
      "\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
      "\n",
      "It is possible to load only a sub-selection of the categories by passing the\n",
      "list of the categories to load to the\n",
      ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
      "\n",
      "  >>> cats = ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      "\n",
      "  >>> list(newsgroups_train.target_names)\n",
      "  ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "Converting text to vectors\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "In order to feed predictive or clustering models with the text data,\n",
      "one first need to turn the text into vectors of numerical values suitable\n",
      "for statistical analysis. This can be achieved with the utilities of the\n",
      "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
      "example that extract `TF-IDF`_ vectors of unigram tokens\n",
      "from a subset of 20news::\n",
      "\n",
      "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
      "  ...               'comp.graphics', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectorizer = TfidfVectorizer()\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> vectors.shape\n",
      "  (2034, 34118)\n",
      "\n",
      "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
      "components by sample in a more than 30000-dimensional space\n",
      "(less than .5% non-zero features)::\n",
      "\n",
      "  >>> vectors.nnz / float(vectors.shape[0])\n",
      "  159.01327...\n",
      "\n",
      ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
      "returns ready-to-use token counts features instead of file names.\n",
      "\n",
      ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
      ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
      "\n",
      "\n",
      "Filtering text for more realistic training\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "It is easy for a classifier to overfit on particular things that appear in the\n",
      "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
      "high F-scores, but their results would not generalize to other documents that\n",
      "aren't from this window of time.\n",
      "\n",
      "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
      "which is fast to train and achieves a decent F-score::\n",
      "\n",
      "  >>> from sklearn.naive_bayes import MultinomialNB\n",
      "  >>> from sklearn import metrics\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.88213...\n",
      "\n",
      "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
      "the training and test data, instead of segmenting by time, and in that case\n",
      "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
      "yet of what's going on inside this classifier?)\n",
      "\n",
      "Let's take a look at what the most informative features are:\n",
      "\n",
      "  >>> import numpy as np\n",
      "  >>> def show_top10(classifier, vectorizer, categories):\n",
      "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "  ...     for i, category in enumerate(categories):\n",
      "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
      "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
      "  ...\n",
      "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
      "  alt.atheism: edu it and in you that is of to the\n",
      "  comp.graphics: edu in graphics it is for and of to the\n",
      "  sci.space: edu it that is in and space to of the\n",
      "  talk.religion.misc: not it you in is that and to of the\n",
      "\n",
      "\n",
      "You can now see many things that these features have overfit to:\n",
      "\n",
      "- Almost every group is distinguished by whether headers such as\n",
      "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
      "- Another significant feature involves whether the sender is affiliated with\n",
      "  a university, as indicated either by their headers or their signature.\n",
      "- The word \"article\" is a significant feature, based on how often people quote\n",
      "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
      "  wrote:\"\n",
      "- Other features match the names and e-mail addresses of particular people who\n",
      "  were posting at the time.\n",
      "\n",
      "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
      "barely have to identify topics from text at all, and they all perform at the\n",
      "same high level.\n",
      "\n",
      "For this reason, the functions that load 20 Newsgroups data provide a\n",
      "parameter called **remove**, telling it what kinds of information to strip out\n",
      "of each file. **remove** should be a tuple containing any subset of\n",
      "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
      "blocks, and quotation blocks respectively.\n",
      "\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
      "  0.77310...\n",
      "\n",
      "This classifier lost over a lot of its F-score, just because we removed\n",
      "metadata that has little to do with topic classification.\n",
      "It loses even more if we also strip this metadata from the training data:\n",
      "\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.76995...\n",
      "\n",
      "Some other classifiers cope better with this harder version of the task. Try\n",
      "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
      "the ``--filter`` option to compare the results.\n",
      "\n",
      ".. topic:: Recommendation\n",
      "\n",
      "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
      "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
      "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
      "  lower because it is more realistic.\n",
      "\n",
      ".. topic:: Examples\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KyeEVD5fyy3"
   },
   "source": [
    "Посмотрим на названия тем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "UwzHtt33a1QG",
    "outputId": "890d7dc9-a77d-48bc-8219-2a9b2b3051f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4Clw6UZeszl"
   },
   "source": [
    "Посмотрим на сами тексты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "U68Sk-iFelOI",
    "outputId": "692a9385-dda7-4b85-833a-ef72890720bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\",\n",
       " \"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\",\n",
       " 'From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n',\n",
       " 'From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It\\'s got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek\\'s address/phone number?  I\\'d like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n',\n",
       " 'From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\\nSubject: Re: Shuttle Launch Question\\nOrganization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\\nDistribution: sci\\nLines: 23\\n\\nFrom article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\\n>>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\\n>>>\"Clear caution & warning memory.  Verify no unexpected\\n>>>errors. ...\".  I am wondering what an \"expected error\" might\\n>>>be.  Sorry if this is a really dumb question, but\\n> \\n> Parity errors in memory or previously known conditions that were waivered.\\n>    \"Yes that is an error, but we already knew about it\"\\n> I\\'d be curious as to what the real meaning of the quote is.\\n> \\n> tom\\n\\n\\nMy understanding is that the \\'expected errors\\' are basically\\nknown bugs in the warning system software - things are checked\\nthat don\\'t have the right values in yet because they aren\\'t\\nset till after launch, and suchlike. Rather than fix the code\\nand possibly introduce new bugs, they just tell the crew\\n\\'ok, if you see a warning no. 213 before liftoff, ignore it\\'.\\n\\n - Jonathan\\n\\n\\n',\n",
       " 'From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\nSubject: Re: Rewording the Second Amendment (ideas)\\nOrganization: VTT\\nLines: 58\\n\\nIn article <1r1eu1$4t@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\\n>In article <1993Apr20.083057.16899@ousrvr.oulu.fi>, dfo@vttoulu.tko.vtt.fi (Foxvog Douglas) writes:\\n>> In article <1qv87v$4j3@transfer.stratus.com> cdt@sw.stratus.com (C. D. Tavares) writes:\\n>> >In article <C5n3GI.F8F@ulowell.ulowell.edu>, jrutledg@cs.ulowell.edu (John Lawrence Rutledge) writes:\\n>\\n>> >> The massive destructive power of many modern weapons, makes the\\n>> >> cost of an accidental or crimial usage of these weapons to great.\\n>> >> The weapons of mass destruction need to be in the control of\\n>> >> the government only.  Individual access would result in the\\n>> >> needless deaths of millions.  This makes the right of the people\\n>> >> to keep and bear many modern weapons non-existant.\\n\\n>> >Thanks for stating where you\\'re coming from.  Needless to say, I\\n>> >disagree on every count.\\n\\n>> You believe that individuals should have the right to own weapons of\\n>> mass destruction?  I find it hard to believe that you would support a \\n>> neighbor\\'s right to keep nuclear weapons, biological weapons, and nerve\\n>> gas on his/her property.  \\n\\n>> If we cannot even agree on keeping weapons of mass destruction out of\\n>> the hands of individuals, can there be any hope for us?\\n\\n>I don\\'t sign any blank checks.\\n\\nOf course.  The term must be rigidly defined in any bill.\\n\\n>When Doug Foxvog says \"weapons of mass destruction,\" he means CBW and\\n>nukes.  When Sarah Brady says \"weapons of mass destruction\" she means\\n>Street Sweeper shotguns and semi-automatic SKS rifles.  \\n\\nI doubt she uses this term for that.  You are using a quote allegedly\\nfrom her, can you back it up?\\n\\n>When John\\n>Lawrence Rutledge says \"weapons of mass destruction,\" and then immediately\\n>follows it with:\\n\\n>>> The US has thousands of people killed each year by handguns,\\n>>> this number can easily be reduced by putting reasonable restrictions\\n>>> on them.\\n\\n>...what does Rutledge mean by the term?\\n\\nI read the article as presenting first an argument about weapons of mass\\ndestruction (as commonly understood) and then switching to other topics.\\nThe first point evidently was to show that not all weapons should be\\nallowed, and then the later analysis was, given this understanding, to\\nconsider another class.\\n\\n>cdt@rocket.sw.stratus.com   --If you believe that I speak for my company,\\n>OR cdt@vos.stratus.com        write today for my special Investors\\' Packet...\\n\\n\\n\\n-- \\ndoug foxvog\\ndouglas.foxvog@vtt.fi\\n',\n",
       " 'From: bmdelane@quads.uchicago.edu (brian manning delaney)\\nSubject: Brain Tumor Treatment (thanks)\\nReply-To: bmdelane@midway.uchicago.edu\\nOrganization: University of Chicago\\nLines: 12\\n\\nThere were a few people who responded to my request for info on\\ntreatment for astrocytomas through email, whom I couldn\\'t thank\\ndirectly because of mail-bouncing probs (Sean, Debra, and Sharon).  So\\nI thought I\\'d publicly thank everyone.\\n\\nThanks! \\n\\n(I\\'m sure glad I accidentally hit \"rn\" instead of \"rm\" when I was\\ntrying to delete a file last September. \"Hmmm... \\'News?\\' What\\'s\\nthis?\"....)\\n\\n-Brian\\n',\n",
       " 'From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: Re: IDE vs SCSI\\nOrganization: New Mexico State University, Las Cruces, NM\\nLines: 44\\nDistribution: world\\nNNTP-Posting-Host: dante.nmsu.edu\\n\\nDXB132@psuvm.psu.edu writes:\\n>In article <1qlbrlINN7rk@dns1.NMSU.Edu>, bgrubb@dante.nmsu.edu (GRUBB) says:\\n>>In PC Magazine April 27, 1993:29 \"Although SCSI is twice as fasst as ESDI,\\n>>20% faster than IDE, and support up to 7 devices its acceptance ...has   \\n>>long been stalled by incompatability problems and installation headaches.\"\\n                                                                      \\n>I love it when magazine writers make stupid statements like that re:      \\n>performance. Where do they get those numbers? I\\'ll list the actual\\n>performance ranges, which should convince anyone that such a               \\n>statement is absurd:                                                     \\n>SCSI-I ranges from 0-5MB/s.                                                \\n>SCSI-II ranges from 0-40MB/s.            \\n>IDE ranges from 0-8.3MB/s.                          \\n>ESDI is always 1.25MB/s (although there are some non-standard versions)\\nALL this shows is that YOU don\\'t know much about SCSI.\\n\\nSCSI-1 {with a SCSI-1 controler chip} range is indeed 0-5MB/s\\nand that is ALL you have right about SCSI\\nSCSI-1 {With a SCSI-2 controller chip}: 4-6MB/s with 10MB/s burst {8-bit}\\n Note the INCREASE in SPEED, the Mac Quadra uses this version of SCSI-1\\n so it DOES exist. Some PC use this set up too.\\nSCSI-2 {8-bit/SCSI-1 mode}:          4-6MB/s with 10MB/s burst\\nSCSI-2 {16-bit/wide or fast mode}:  8-12MB/s with 20MB/s burst\\nSCSI-2 {32-bit/wide AND fast}:     15-20MB/s with 40MB/s burst\\n \\nBy your OWN data the \"Although SCSI is twice as fast as ESDI\" is correct\\nWith a SCSI-2 controller chip SCSI-1 can reach 10MB/s which is indeed\\n\"20% faster than IDE\" {120% of 8.3 is 9.96}. ALL these SCSI facts have been\\nposted to this newsgroup in my Mac & IBM info sheet {available by FTP on \\nsumex-aim.stanford.edu (36.44.0.6) in the info-mac/report as \\nmac-ibm-compare[version #].txt (It should be 173 but 161 may still be there)}\\n\\nPart of this problem is both Mac and IBM PC are inconsiant about what SCSI\\nis which.  Though it is WELL documented that the Quadra has a SCSI-2 chip\\nan Apple salesperson said \"it uses a fast SCSI-1 chip\" {Not at a 6MB/s,\\n10MB/s burst it does not. SCSI-1 is 5MB/s maximum synchronous and Quadra\\nuses ANsynchronous SCSI which is SLOWER}  It seems that Mac and IBM see\\nSCSI-1 interface and think \\'SCSI-1\\' when it maybe a SCSI-1 interface driven\\nin the machine by a SCSi-2 controller chip in 8-bit mode {Which is MUCH\\nFASTER then true SCSI-1 can go}.\\n\\nDon\\'t slam an article because you don\\'t understand what is going on.\\nOne reference for the Quadra\\'s SCSI-2 controller chip is \\n(Digital Review, Oct 21, 1991 v8 n33 p8(1)).\\n',\n",
       " 'From: holmes7000@iscsvax.uni.edu\\nSubject: WIn 3.0 ICON HELP PLEASE!\\nOrganization: University of Northern Iowa\\nLines: 10\\n\\nI have win 3.0 and downloaded several icons and BMP\\'s but I can\\'t figure out\\nhow to change the \"wallpaper\" or use the icons.  Any help would be appreciated.\\n\\n\\nThanx,\\n\\n-Brando\\n\\nPS Please E-mail me\\n\\n',\n",
       " \"From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubject: Re: Sigma Designs Double up??\\nArticle-I.D.: ux1.C52u8x.B62\\nOrganization: University of Illinois at Urbana\\nLines: 29\\n\\njap10@po.CWRU.Edu (Joseph A. Pellettiere) writes:\\n\\n\\n>\\tI am looking for any information about the Sigma Designs\\n>\\tdouble up board.  All I can figure out is that it is a\\n>\\thardware compression board that works with AutoDoubler, but\\n>\\tI am not sure about this.  Also how much would one cost?\\n\\nI've had the board for over a year, and it does work with Diskdoubler,\\nbut not with Autodoubler, due to a licensing problem with Stac Technologies,\\nthe owners of the board's compression technology. (I'm writing this\\nfrom memory; I've lost the reference. Please correct me if I'm wrong.)\\n\\nUsing the board, I've had problems with file icons being lost, but it's\\nhard to say whether it's the board's fault or something else; however,\\nif I decompress the troubled file and recompress it without the board,\\nthe icon usually reappears. Because of the above mentioned licensing\\nproblem, the freeware expansion utility DD Expand will not decompress\\na board-compressed file unless you have the board installed.\\n\\nSince Stac has its own product now, it seems unlikely that the holes\\nin Autodoubler/Diskdoubler related to the board will be fixed.\\nWhich is sad, and makes me very reluctant to buy Stac's product since\\nthey're being so stinky. (But hey, that's competition.)\\n-- \\n\\nStan Kerr    \\nComputing & Communications Services Office, U of Illinois/Urbana\\nPhone: 217-333-5217  Email: stankerr@uiuc.edu   \\n\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKZfgSitV7aG"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = newsgroups.data\n",
    "df['target'] = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "XUNuH_fZWAZ-",
    "outputId": "db4fa475-57bc-483e-f9e3-0ea7941efb42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14\n",
       "5  From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...      16\n",
       "6  From: bmdelane@quads.uchicago.edu (brian manni...      13\n",
       "7  From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...       3\n",
       "8  From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...       2\n",
       "9  From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...       4"
      ]
     },
     "execution_count": 148,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IReUeP0sXFC2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UDgt-_EW5yt"
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(123)\n",
    "df_train, df_test = train_test_split(df, train_size=0.5, test_size=0.3, stratify=df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UatYkFqiXWXV",
    "outputId": "837a5d1b-0b12-402d-a900-6e2bf9bd07e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 2)"
      ]
     },
     "execution_count": 151,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8WS2uKo9DiAA"
   },
   "source": [
    "# Преобразовать текстовые данные в признаки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YUhhivGf5k0"
   },
   "source": [
    "## 1. Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mssvi4Ks1aM"
   },
   "source": [
    "Каждый документ - мешок слов. Не важно в каком они порядке, не важно как они связаны между собой, вообще ничего не важно кроме того, какие именно слова есть в документе и в каком количестве. \n",
    "\n",
    "------------------------------------\n",
    "![bow](http://uc-r.github.io/public/images/analytics/feature-engineering/bow-image.png)\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XY0zmtO3vBYO"
   },
   "source": [
    "Процесс преобразования:\n",
    "1. Токенизация \n",
    "2. (Предобработка)\n",
    "3. Построение словаря по всем документам коллекции\n",
    "4. Вектор признаков для кажого документа - количество вхождений каждого слова из словаря в документ\n",
    "\n",
    "----------------------------------------\n",
    "![bow2](https://raw.githubusercontent.com/Yorko/mlcourse.ai/3380f07cebee0b44a6cc9e1d4e36eb4675ae37fd/img/bag_of_words.png)\n",
    "\n",
    "---------------------------------\n",
    "Итоговая матрица признаков получается \n",
    "+ очень большой (***Кол-во объектов*** х ***Размер словаря***) \n",
    "+ очень разреженной (много 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPng13xIUl0p"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7tZjXWnYiFv"
   },
   "source": [
    "`sklearn.feature_extraction.text.CountVectorizer`\n",
    "+ ***fit*** - строит словарь по коллекции текстов\n",
    "+ ***transform*** - преобразует коллекцию текстов в матрицу признаков по полученному после ***fit*** словарю \n",
    "+ по умолчанию в качестве элемента словаря выступают отдельные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rcDMB1jUt39"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7BYjjuusUyf4",
    "outputId": "6d2e8bc5-c198-42b1-d145-0f46d9005214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 940 µs, total: 2.18 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = vectorizer.fit_transform(df_train.text) # постоить словарь по обучающей выборке и преобразовать ее в матрицу\n",
    "X_test = vectorizer.transform(df_test.text) # преобразовать тестовую выборку в матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ok2MURGyaFeo",
    "outputId": "70aa1b67-47b7-4547-b6a7-4f3f34771d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 85615 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря: %s элементов' % X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v39UkDdA-JoY",
    "outputId": "f00e3789-a180-4917-85b8-d54f30dc9049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 36822,\n",
       " 'nrmendel': 57333,\n",
       " 'unix': 78596,\n",
       " 'amherst': 16431,\n",
       " 'edu': 32315,\n",
       " 'nathaniel': 56003,\n",
       " 'mendell': 52699,\n",
       " 'subject': 73314,\n",
       " 're': 65114,\n",
       " 'opinions': 58624,\n",
       " 'wanted': 81347,\n",
       " 'help': 40656,\n",
       " 'nntp': 56952,\n",
       " 'posting': 62063,\n",
       " 'host': 41582,\n",
       " 'amhux3': 16433,\n",
       " 'organization': 58817,\n",
       " 'college': 25539,\n",
       " 'newsreader': 56532,\n",
       " 'tin': 76035,\n",
       " 'version': 80071,\n",
       " 'pl7': 61377,\n",
       " 'lines': 49392,\n",
       " 'what': 81899,\n",
       " 'size': 70733,\n",
       " 'dirtbikes': 30181,\n",
       " 'did': 29962,\n",
       " 'you': 84600,\n",
       " 'ride': 66777,\n",
       " 'and': 16647,\n",
       " 'for': 36322,\n",
       " 'how': 41650,\n",
       " 'long': 49844,\n",
       " 'might': 53289,\n",
       " 'be': 19547,\n",
       " 'able': 14687,\n",
       " 'to': 76196,\n",
       " 'slip': 71013,\n",
       " 'into': 44229,\n",
       " '500cc': 8545,\n",
       " 'bike': 20283,\n",
       " 'like': 49295,\n",
       " 'keep': 46838,\n",
       " 'telling': 75175,\n",
       " 'people': 60521,\n",
       " 'though': 75765,\n",
       " 'buy': 22077,\n",
       " 'an': 16557,\n",
       " 'older': 58337,\n",
       " 'cheaper': 24182,\n",
       " 'that': 75513,\n",
       " 'while': 81951,\n",
       " 'first': 35815,\n",
       " '500': 8534,\n",
       " 'interceptor': 44055,\n",
       " 'as': 17697,\n",
       " 'example': 34160,\n",
       " 'zx': 85566,\n",
       " '10': 1208,\n",
       " 'dod': 30889,\n",
       " '0812': 713,\n",
       " 'ama': 16348,\n",
       " 'hans': 40098,\n",
       " 'xelion': 83402,\n",
       " 'nl': 56898,\n",
       " 'bos': 21101,\n",
       " 'save': 68609,\n",
       " 'under': 78275,\n",
       " 'with': 82344,\n",
       " 'x11r5': 83044,\n",
       " 'keywords': 47020,\n",
       " 'bv': 22091,\n",
       " '26': 5624,\n",
       " 'have': 40335,\n",
       " 'the': 75524,\n",
       " 'following': 36264,\n",
       " 'problem': 62715,\n",
       " 'on': 58458,\n",
       " 'servers': 69681,\n",
       " 'when': 81928,\n",
       " 'window': 82212,\n",
       " 'of': 58119,\n",
       " 'my': 55515,\n",
       " 'is': 44593,\n",
       " 'obscured': 57900,\n",
       " 'by': 22140,\n",
       " 'pop': 61905,\n",
       " 'up': 78893,\n",
       " 'which': 81946,\n",
       " 'has': 40259,\n",
       " 'attribute': 18192,\n",
       " 'set': 69704,\n",
       " 'subwindows': 73434,\n",
       " 'are': 17425,\n",
       " 'not': 57186,\n",
       " 'restored': 66369,\n",
       " 'normally': 57138,\n",
       " 'redrawn': 65490,\n",
       " 'parent': 59905,\n",
       " 'gets': 38028,\n",
       " 'expose': 34452,\n",
       " 'event': 34023,\n",
       " 'but': 22035,\n",
       " 'because': 19629,\n",
       " 'used': 79079,\n",
       " 'no': 56957,\n",
       " 'sent': 69551,\n",
       " 'exposuremask': 34458,\n",
       " 'child': 24333,\n",
       " 'windows': 82217,\n",
       " 'those': 75759,\n",
       " 'correctly': 26851,\n",
       " 'updated': 78908,\n",
       " 'popup': 61934,\n",
       " 'disappears': 30208,\n",
       " 'however': 41661,\n",
       " 'then': 75569,\n",
       " 'application': 17173,\n",
       " 'too': 76339,\n",
       " 'many': 51490,\n",
       " 'events': 34029,\n",
       " 'see': 69343,\n",
       " 'extra': 34522,\n",
       " 'redraws': 65491,\n",
       " 'everything': 34059,\n",
       " 'works': 82615,\n",
       " 'fine': 35740,\n",
       " 'x11r4': 83042,\n",
       " 'this': 75718,\n",
       " 'something': 71534,\n",
       " 'changed': 24083,\n",
       " 'between': 20069,\n",
       " 'obvious': 57948,\n",
       " 'it': 44750,\n",
       " 'do': 30840,\n",
       " 'wrong': 82784,\n",
       " 'there': 75611,\n",
       " 'should': 70242,\n",
       " 'also': 16263,\n",
       " 'mine': 53449,\n",
       " 'bug': 21809,\n",
       " 'in': 43173,\n",
       " 'x11': 83038,\n",
       " 'release': 65811,\n",
       " 'greetings': 39050,\n",
       " 'domain': 30959,\n",
       " 'uucp': 79235,\n",
       " 'sun4nl': 73612,\n",
       " 'postbus': 62047,\n",
       " '88': 11964,\n",
       " 'phone': 60980,\n",
       " '31': 6565,\n",
       " '15': 2398,\n",
       " '622121': 9567,\n",
       " 'nanderso': 55922,\n",
       " 'endor': 33112,\n",
       " 'sim': 70540,\n",
       " 'es': 33683,\n",
       " 'com': 25615,\n",
       " 'norman': 57140,\n",
       " 'anderson': 16655,\n",
       " 'wrench': 82742,\n",
       " 'evans': 34000,\n",
       " 'sutherland': 73962,\n",
       " 'computer': 25985,\n",
       " 'corp': 26828,\n",
       " '13': 1917,\n",
       " 'jmcocker': 45750,\n",
       " 'eos': 33399,\n",
       " 'ncsu': 56136,\n",
       " 'mitch': 53709,\n",
       " 'writes': 82770,\n",
       " 'effect': 32383,\n",
       " 'one': 58474,\n",
       " 'ssrbs': 72405,\n",
       " 'was': 81423,\n",
       " 'recovered': 65405,\n",
       " 'after': 15589,\n",
       " 'recent': 65296,\n",
       " 'space': 71702,\n",
       " 'shuttle': 70335,\n",
       " 'launch': 48500,\n",
       " 'found': 36510,\n",
       " 'some': 71515,\n",
       " 'sort': 71618,\n",
       " 'rattling': 64883,\n",
       " 'around': 17584,\n",
       " 'apparently': 17119,\n",
       " 'inside': 43845,\n",
       " 'case': 23401,\n",
       " 'heard': 40493,\n",
       " 'similar': 70550,\n",
       " 'statement': 72624,\n",
       " 'our': 59080,\n",
       " 'local': 49730,\n",
       " 'news': 56501,\n",
       " 'utah': 79158,\n",
       " 'tonight': 76323,\n",
       " 'they': 75656,\n",
       " 'referred': 65556,\n",
       " 'tool': 76344,\n",
       " 'pliers': 61533,\n",
       " 'took': 76341,\n",
       " 'said': 68285,\n",
       " 'thiokol': 75707,\n",
       " 'sp': 71693,\n",
       " 'employee': 32969,\n",
       " 'had': 39830,\n",
       " 'reported': 66103,\n",
       " 'missing': 53663,\n",
       " 'kind': 47204,\n",
       " 'during': 31672,\n",
       " 'assembly': 17867,\n",
       " 'srb': 72281,\n",
       " 'more': 54421,\n",
       " 'info': 43591,\n",
       " 'location': 49745,\n",
       " 'agree': 15693,\n",
       " 'pretty': 62540,\n",
       " 'weird': 81724,\n",
       " 'leech': 48759,\n",
       " 'cs': 27542,\n",
       " 'unc': 78193,\n",
       " 'jon': 45886,\n",
       " 'faq': 35056,\n",
       " '14': 2154,\n",
       " 'become': 19644,\n",
       " 'astronaut': 17973,\n",
       " 'frequently': 36750,\n",
       " 'asked': 17787,\n",
       " 'questions': 64191,\n",
       " 'article': 17663,\n",
       " 'astronaut_733694515': 17975,\n",
       " 'expires': 34399,\n",
       " 'may': 51942,\n",
       " '1993': 3585,\n",
       " '20': 4643,\n",
       " '01': 130,\n",
       " '55': 8807,\n",
       " 'gmt': 38492,\n",
       " 'distribution': 30595,\n",
       " 'world': 82623,\n",
       " 'university': 78593,\n",
       " 'north': 57147,\n",
       " 'carolina': 23323,\n",
       " 'chapel': 24103,\n",
       " 'hill': 40993,\n",
       " '313': 6584,\n",
       " 'supersedes': 73758,\n",
       " 'astronaut_730956661': 17974,\n",
       " 'mahler': 51146,\n",
       " 'archive': 17402,\n",
       " 'name': 55904,\n",
       " 'last': 48441,\n",
       " 'modified': 54127,\n",
       " 'date': 28536,\n",
       " '93': 12609,\n",
       " '04': 407,\n",
       " '39': 7124,\n",
       " '02': 237,\n",
       " 'short': 70206,\n",
       " 'form': 36410,\n",
       " 'authored': 18319,\n",
       " 'henry': 40719,\n",
       " 'spencer': 71926,\n",
       " 'official': 58163,\n",
       " 'nasa': 55965,\n",
       " 'announcement': 16799,\n",
       " 'we': 81611,\n",
       " 'will': 82145,\n",
       " 'assume': 17919,\n",
       " 'mean': 52416,\n",
       " 'since': 70609,\n",
       " 'probably': 62700,\n",
       " 'impossible': 43103,\n",
       " 'non': 57033,\n",
       " 'russian': 67811,\n",
       " 'get': 38010,\n",
       " 'cosmonaut': 26912,\n",
       " 'corps': 26837,\n",
       " 'paying': 60217,\n",
       " 'passengers': 60054,\n",
       " 'professional': 62798,\n",
       " 'cosmonauts': 26913,\n",
       " 'other': 59027,\n",
       " 'nations': 56023,\n",
       " 'so': 71335,\n",
       " 'few': 35491,\n",
       " 'astronauts': 17978,\n",
       " 'fly': 36142,\n",
       " 'even': 34015,\n",
       " 'fewer': 35492,\n",
       " 'better': 20060,\n",
       " 'off': 58131,\n",
       " 'hoping': 41489,\n",
       " 'win': 82192,\n",
       " 'lottery': 49939,\n",
       " 'becoming': 19646,\n",
       " 'pilot': 61188,\n",
       " 'requires': 66183,\n",
       " 'lots': 49937,\n",
       " 'fast': 35125,\n",
       " 'jet': 45465,\n",
       " 'experience': 34377,\n",
       " 'means': 52425,\n",
       " 'military': 53367,\n",
       " 'flying': 36149,\n",
       " 'career': 23274,\n",
       " 'forget': 36391,\n",
       " 'unless': 78624,\n",
       " 'want': 81346,\n",
       " 'anyway': 16987,\n",
       " 'mission': 53665,\n",
       " 'specialist': 71825,\n",
       " 'if': 42660,\n",
       " 'aren': 17429,\n",
       " 'us': 79048,\n",
       " 'citizen': 24806,\n",
       " 'must': 55302,\n",
       " 'crucial': 27447,\n",
       " 'thing': 75686,\n",
       " 'remember': 65908,\n",
       " 'demand': 29251,\n",
       " 'such': 73463,\n",
       " 'jobs': 45797,\n",
       " 'vastly': 79756,\n",
       " 'exceeds': 34172,\n",
       " 'supply': 73794,\n",
       " 'finding': 35737,\n",
       " 'qualified': 64100,\n",
       " 'thinning': 75703,\n",
       " 'lineup': 49397,\n",
       " 'down': 31142,\n",
       " 'manageable': 51346,\n",
       " 'length': 48885,\n",
       " 'enough': 33237,\n",
       " 'avoid': 18475,\n",
       " 'being': 19770,\n",
       " 'dis': 30185,\n",
       " 'any': 16969,\n",
       " 'reason': 65226,\n",
       " 'them': 75559,\n",
       " 'principle': 62621,\n",
       " 'quite': 64243,\n",
       " 'irrelevant': 44559,\n",
       " 'job': 45794,\n",
       " 'ph': 60865,\n",
       " 'specialize': 71828,\n",
       " 'involves': 44365,\n",
       " 'getting': 38032,\n",
       " 'your': 84615,\n",
       " 'hands': 40062,\n",
       " 'dirty': 30184,\n",
       " 'equipment': 33534,\n",
       " 'just': 46220,\n",
       " 'paper': 59816,\n",
       " 'pencil': 60464,\n",
       " 'programming': 62840,\n",
       " 'entirely': 33301,\n",
       " 'done': 31005,\n",
       " 'ground': 39178,\n",
       " 'fore': 36344,\n",
       " 'seeable': 69344,\n",
       " 'future': 37101,\n",
       " 'degree': 29126,\n",
       " 'field': 35603,\n",
       " 'plus': 61588,\n",
       " 'work': 82597,\n",
       " 'another': 16839,\n",
       " 'seems': 69363,\n",
       " 'frequent': 36749,\n",
       " 'winner': 82268,\n",
       " 'good': 38672,\n",
       " 'physical': 61057,\n",
       " 'condition': 26115,\n",
       " 'eyesight': 34585,\n",
       " 'radial': 64589,\n",
       " 'keratomy': 46930,\n",
       " 'or': 58729,\n",
       " 'hack': 39821,\n",
       " 'improve': 43133,\n",
       " 'vision': 80394,\n",
       " 'nobody': 56977,\n",
       " 'knows': 47523,\n",
       " 'sudden': 73479,\n",
       " 'pressure': 62502,\n",
       " 'changes': 24087,\n",
       " 'would': 82669,\n",
       " 'rked': 66998,\n",
       " 'eyes': 34584,\n",
       " 'term': 75300,\n",
       " 'effects': 32390,\n",
       " 'poorly': 61904,\n",
       " 'understood': 78343,\n",
       " 'matter': 51855,\n",
       " 'significant': 70476,\n",
       " 'medical': 52504,\n",
       " 'unknowns': 78613,\n",
       " 'can': 23075,\n",
       " 'pass': 60042,\n",
       " 'okay': 58285,\n",
       " 'chances': 24074,\n",
       " 'poor': 61899,\n",
       " 'practise': 62216,\n",
       " 'public': 63310,\n",
       " 'speaking': 71808,\n",
       " 'conservative': 26342,\n",
       " 'conformist': 26210,\n",
       " 'appearance': 17130,\n",
       " 'actions': 15114,\n",
       " 've': 79867,\n",
       " 'got': 38736,\n",
       " 'tough': 76466,\n",
       " 'selling': 69459,\n",
       " 'ahead': 15739,\n",
       " 'trying': 77096,\n",
       " 'convince': 26667,\n",
       " 'cautious': 23550,\n",
       " 'selection': 69435,\n",
       " 'committee': 25739,\n",
       " 'than': 75496,\n",
       " 'hundreds': 41972,\n",
       " 'applicants': 17172,\n",
       " 'credit': 27272,\n",
       " 'hired': 41062,\n",
       " 'relations': 65790,\n",
       " 'part': 59970,\n",
       " 'image': 42890,\n",
       " 'very': 80096,\n",
       " 'prim': 62591,\n",
       " 'proper': 62961,\n",
       " 'squeaky': 72232,\n",
       " 'clean': 25018,\n",
       " 'workaholic': 82599,\n",
       " 'yuppie': 84736,\n",
       " 'need': 56225,\n",
       " 'security': 69327,\n",
       " 'clearance': 25034,\n",
       " 'at': 18018,\n",
       " 'point': 61732,\n",
       " 'considers': 26355,\n",
       " 'everybody': 34051,\n",
       " 'guilty': 39411,\n",
       " 'until': 78827,\n",
       " 'proven': 63106,\n",
       " 'innocent': 43770,\n",
       " 'nose': 57171,\n",
       " 'license': 49200,\n",
       " 'make': 51238,\n",
       " 'number': 57460,\n",
       " 'hobby': 41242,\n",
       " 'experienced': 34379,\n",
       " 'pilots': 61190,\n",
       " 'known': 47522,\n",
       " 'favored': 35179,\n",
       " '45': 7927,\n",
       " 'selected': 69433,\n",
       " '1984': 3565,\n",
       " '1988': 3571,\n",
       " '43': 7831,\n",
       " 'were': 81779,\n",
       " 'employees': 32970,\n",
       " 'remaining': 65884,\n",
       " 'two': 77428,\n",
       " 'consultant': 26449,\n",
       " 'mae': 51060,\n",
       " 'jemison': 45413,\n",
       " 'black': 20523,\n",
       " 'female': 35396,\n",
       " 'apply': 17186,\n",
       " 'outside': 59165,\n",
       " 'miss': 53656,\n",
       " 'offer': 58147,\n",
       " 'take': 74709,\n",
       " 'sometimes': 71539,\n",
       " 'past': 60075,\n",
       " 'meant': 52426,\n",
       " 'look': 49866,\n",
       " 'interesting': 44082,\n",
       " 'know': 47507,\n",
       " 'bit': 20441,\n",
       " 'think': 75692,\n",
       " 'highly': 40969,\n",
       " 'motivated': 54540,\n",
       " 'lose': 49925,\n",
       " 'chance': 24071,\n",
       " 'demonstrate': 29303,\n",
       " 'motivation': 54543,\n",
       " 'didn': 29968,\n",
       " 'time': 75994,\n",
       " 'national': 56007,\n",
       " 'aeronautics': 15471,\n",
       " 'administration': 15291,\n",
       " 'lyndon': 50330,\n",
       " 'johnson': 45852,\n",
       " 'center': 23835,\n",
       " 'houston': 41642,\n",
       " 'texas': 75423,\n",
       " 'candidates': 23110,\n",
       " 'candidate': 23109,\n",
       " 'program': 62826,\n",
       " 'support': 73796,\n",
       " 'now': 57254,\n",
       " 'accepting': 14869,\n",
       " 'continuous': 26534,\n",
       " 'basis': 19342,\n",
       " 'plans': 61429,\n",
       " 'select': 69431,\n",
       " 'needed': 56226,\n",
       " 'persons': 60713,\n",
       " 'both': 21120,\n",
       " 'civilian': 24824,\n",
       " 'sector': 69318,\n",
       " 'services': 69687,\n",
       " 'considered': 26353,\n",
       " 'all': 16125,\n",
       " 'positions': 62013,\n",
       " 'located': 49743,\n",
       " 'involved': 44363,\n",
       " 'year': 84378,\n",
       " 'training': 76631,\n",
       " 'evaluation': 33989,\n",
       " 'description': 29520,\n",
       " 'numerous': 57475,\n",
       " 'successful': 73447,\n",
       " 'flights': 36030,\n",
       " 'demonstrated': 29304,\n",
       " 'operation': 58605,\n",
       " 'experimental': 34383,\n",
       " 'investigations': 44334,\n",
       " 'routine': 67483,\n",
       " 'orbiter': 58747,\n",
       " 'launched': 48502,\n",
       " 'maneuvers': 51381,\n",
       " 'earth': 32026,\n",
       " 'orbit': 58744,\n",
       " 'performing': 60582,\n",
       " 'missions': 53668,\n",
       " 'lastling': 48445,\n",
       " '30': 6466,\n",
       " 'days': 28631,\n",
       " 'returns': 66486,\n",
       " 'ready': 65164,\n",
       " 'flight': 36029,\n",
       " 'payloads': 60219,\n",
       " 'crew': 27301,\n",
       " 'performs': 60584,\n",
       " 'variety': 79728,\n",
       " 'orbital': 58745,\n",
       " 'including': 43262,\n",
       " 'deployment': 29415,\n",
       " 'retrieval': 66469,\n",
       " 'satellites': 68551,\n",
       " 'service': 69683,\n",
       " 'existing': 34299,\n",
       " 'specialized': 71829,\n",
       " 'laboratories': 48184,\n",
       " 'astronomy': 17985,\n",
       " 'sciences': 68926,\n",
       " 'materials': 51808,\n",
       " 'processing': 62745,\n",
       " 'manufacturing': 51479,\n",
       " 'operations': 58609,\n",
       " 'these': 75641,\n",
       " 'eventually': 34032,\n",
       " 'include': 43258,\n",
       " 'development': 29732,\n",
       " 'servicing': 69688,\n",
       " 'permanent': 60629,\n",
       " 'station': 72636,\n",
       " 'provides': 63119,\n",
       " 'staging': 72488,\n",
       " 'capability': 23167,\n",
       " 'using': 79106,\n",
       " 'higher': 40961,\n",
       " 'orbits': 58750,\n",
       " 'achieved': 15011,\n",
       " 'itself': 44815,\n",
       " 'users': 79095,\n",
       " 'capabilities': 23166,\n",
       " 'domestic': 30963,\n",
       " 'foreign': 36360,\n",
       " 'government': 38773,\n",
       " 'agencies': 15637,\n",
       " 'private': 62659,\n",
       " 'industries': 43447,\n",
       " 'consists': 26371,\n",
       " 'five': 35869,\n",
       " 'commander': 25674,\n",
       " 'three': 75791,\n",
       " 'specialists': 71826,\n",
       " 'occasion': 57962,\n",
       " 'additional': 15221,\n",
       " 'members': 52655,\n",
       " 'assigned': 17888,\n",
       " 'server': 69680,\n",
       " 'commanders': 25675,\n",
       " 'onboard': 58467,\n",
       " 'responsibility': 66344,\n",
       " 'vehicle': 79914,\n",
       " 'success': 73445,\n",
       " 'safety': 68260,\n",
       " 'assists': 17902,\n",
       " 'controlling': 26601,\n",
       " 'operating': 58604,\n",
       " 'addition': 15220,\n",
       " 'assist': 17896,\n",
       " 'utilizing': 79182,\n",
       " 'remote': 65942,\n",
       " 'manipulator': 51421,\n",
       " 'system': 74336,\n",
       " 'vehicular': 79916,\n",
       " 'activities': 15127,\n",
       " 'payload': 60218,\n",
       " 'working': 82610,\n",
       " 'overall': 59204,\n",
       " 'coordination': 26722,\n",
       " 'areas': 17428,\n",
       " 'activity': 15129,\n",
       " 'planning': 61428,\n",
       " 'consumables': 26455,\n",
       " 'usage': 79062,\n",
       " 'experiment': 34382,\n",
       " 'required': 66179,\n",
       " 'detailed': 29637,\n",
       " 'knowledge': 47517,\n",
       " 'systems': 74345,\n",
       " 'well': 81754,\n",
       " 'operational': 58606,\n",
       " 'characteristics': 24120,\n",
       " 'requirements': 66181,\n",
       " 'objectives': 57859,\n",
       " 'supporting': 73802,\n",
       " 'each': 31984,\n",
       " 'experiments': 34390,\n",
       " 'conducted': 26133,\n",
       " 'their': 75546,\n",
       " 'perform': 60574,\n",
       " 'handling': 40056,\n",
       " 'specific': 71837,\n",
       " 'basic': 19326,\n",
       " 'qualification': 64098,\n",
       " 'meet': 52548,\n",
       " 'minimum': 53480,\n",
       " 'prior': 62640,\n",
       " 'submitting': 73342,\n",
       " 'bachelor': 18912,\n",
       " 'accredited': 14942,\n",
       " 'institution': 43927,\n",
       " 'engineering': 33174,\n",
       " 'biological': 20380,\n",
       " 'science': 68924,\n",
       " 'mathematics': 51824,\n",
       " 'followed': 36260,\n",
       " 'least': 48712,\n",
       " 'years': 84380,\n",
       " 'related': 65784,\n",
       " 'progressively': 62850,\n",
       " 'responsible': 66347,\n",
       " 'advanced': 15378,\n",
       " 'desirable': 29556,\n",
       " 'substituted': 73401,\n",
       " 'requirement': 66180,\n",
       " 'master': 51771,\n",
       " 'doctoral': 30869,\n",
       " 'quality': 64110,\n",
       " 'academic': 14826,\n",
       " 'preparation': 62430,\n",
       " 'important': 43088,\n",
       " 'ability': 14681,\n",
       " 'class': 24980,\n",
       " 'ii': 42748,\n",
       " 'includes': 43261,\n",
       " 'standards': 72531,\n",
       " 'distant': 30556,\n",
       " 'visual': 80410,\n",
       " 'acuity': 15146,\n",
       " '150': 2399,\n",
       " 'uncorrected': 78253,\n",
       " 'correctable': 26844,\n",
       " 'eye': 34572,\n",
       " 'blood': 20686,\n",
       " '140': 2155,\n",
       " '90': 12455,\n",
       " 'measured': 52434,\n",
       " 'sitting': 70707,\n",
       " 'position': 62009,\n",
       " 'height': 40578,\n",
       " '58': 8974,\n",
       " '76': 11050,\n",
       " 'inches': 43241,\n",
       " '1000': 1210,\n",
       " 'hours': 41628,\n",
       " 'command': 25670,\n",
       " 'aircraft': 15830,\n",
       " 'test': 75370,\n",
       " '50': 8533,\n",
       " '64': 9664,\n",
       " 'citizenship': 24809,\n",
       " 'applications': 17176,\n",
       " 'citizens': 24808,\n",
       " 'united': 78564,\n",
       " 'states': 72627,\n",
       " 'note': 57198,\n",
       " 'education': 32321,\n",
       " 'scientific': 68927,\n",
       " 'specifically': 71839,\n",
       " 'completion': 25891,\n",
       " 'standard': 72527,\n",
       " 'curriculum': 27813,\n",
       " 'leading': 48666,\n",
       " 'major': 51229,\n",
       " 'study': 73220,\n",
       " 'appropriate': 17233,\n",
       " 'fields': 35610,\n",
       " 'qualifying': 64105,\n",
       " 'degrees': 29127,\n",
       " 'technology': 75055,\n",
       " 'aviation': 18459,\n",
       " 'etc': 33828,\n",
       " 'psychology': 63254,\n",
       " 'except': 34180,\n",
       " 'clinical': 25110,\n",
       " 'physiological': 61070,\n",
       " 'nursing': 57501,\n",
       " 'social': 71362,\n",
       " 'geography': 37932,\n",
       " 'anthropology': 16885,\n",
       " 'archaeology': 17374,\n",
       " 'management': 51349,\n",
       " 'procedures': 62731,\n",
       " 'package': 59610,\n",
       " 'obtained': 57939,\n",
       " 'writing': 82772,\n",
       " 'office': 58159,\n",
       " 'attn': 18179,\n",
       " 'ahx': 15776,\n",
       " 'tx': 77439,\n",
       " '77058': 11100,\n",
       " 'accepted': 14867,\n",
       " 'decides': 28859,\n",
       " 'consideration': 26351,\n",
       " 'given': 38253,\n",
       " 'only': 58499,\n",
       " 'hand': 40016,\n",
       " 'decision': 28872,\n",
       " 'made': 51043,\n",
       " 'received': 65290,\n",
       " 'retained': 66412,\n",
       " 'next': 56551,\n",
       " 'notified': 57221,\n",
       " 'annually': 16814,\n",
       " 'opportunity': 58642,\n",
       " 'update': 78907,\n",
       " 'indicate': 43385,\n",
       " 'continued': 26529,\n",
       " 'interest': 44078,\n",
       " 'who': 82017,\n",
       " 'dropped': 31381,\n",
       " 'preliminary': 62408,\n",
       " 'screening': 69048,\n",
       " 'information': 43613,\n",
       " 'requested': 66174,\n",
       " 'person': 60692,\n",
       " 'listed': 49470,\n",
       " 'supervisors': 73777,\n",
       " 'references': 65548,\n",
       " 'contacted': 26470,\n",
       " 'active': 15120,\n",
       " 'duty': 31700,\n",
       " 'personnel': 60712,\n",
       " 'submit': 73339,\n",
       " 'respective': 66323,\n",
       " 'directly': 30169,\n",
       " 'disseminated': 30526,\n",
       " 'personal': 60699,\n",
       " 'interviews': 44210,\n",
       " 'thorough': 75752,\n",
       " 'evaluations': 33990,\n",
       " 'final': 35717,\n",
       " 'once': 58468,\n",
       " 'selections': 69436,\n",
       " 'been': 19687,\n",
       " 'outcome': 59098,\n",
       " 'process': 62741,\n",
       " 'rosters': 67425,\n",
       " 'established': 33790,\n",
       " 'through': 75819,\n",
       " 'period': 60603,\n",
       " 'establishment': 33793,\n",
       " 'general': 37843,\n",
       " 'designated': 29544,\n",
       " 'undergo': 78297,\n",
       " 'technical': 75041,\n",
       " 'responsibilities': 66343,\n",
       " 'allowing': 16195,\n",
       " 'contribute': 26577,\n",
       " 'substantially': 73393,\n",
       " 'ongoing': 58494,\n",
       " 'programs': 62843,\n",
       " 'participate': 59990,\n",
       " 'designed': 29549,\n",
       " 'develop': 29725,\n",
       " 'skills': 70825,\n",
       " 'formal': 36414,\n",
       " 'upon': 78942,\n",
       " 'maintain': 51200,\n",
       " 'proficiency': 62806,\n",
       " 'aware': 18535,\n",
       " 'does': 30908,\n",
       " 'insure': 43968,\n",
       " 'depend': 29392,\n",
       " 'satisfactory': 68562,\n",
       " 'successfully': 73449,\n",
       " 'complete': 25882,\n",
       " 'federal': 35309,\n",
       " 'expected': 34350,\n",
       " 'remain': 65880,\n",
       " 'placed': 61388,\n",
       " 'within': 82360,\n",
       " 'depending': 29400,\n",
       " 'agency': 15638,\n",
       " 'manpower': 51449,\n",
       " 'constraints': 26429,\n",
       " 'specified': 71847,\n",
       " 'tour': 76477,\n",
       " 'affirmative': 15534,\n",
       " 'action': 15113,\n",
       " 'goal': 38534,\n",
       " 'having': 40341,\n",
       " 'minorities': 53506,\n",
       " 'women': 82528,\n",
       " 'among': 16480,\n",
       " 'therefore': 75617,\n",
       " 'encouraged': 33056,\n",
       " 'pay': 60211,\n",
       " 'benefits': 19902,\n",
       " 'civilians': 24825,\n",
       " 'salaries': 68312,\n",
       " 'based': 19308,\n",
       " 'governments': 38776,\n",
       " 'schedule': 68800,\n",
       " 'scales': 68703,\n",
       " 'grades': 38863,\n",
       " 'gs': 39235,\n",
       " '11': 1487,\n",
       " 'accordance': 14923,\n",
       " 'individuals': 43423,\n",
       " 'achievements': 15013,\n",
       " 'vacation': 79577,\n",
       " 'sick': 70389,\n",
       " 'leave': 48717,\n",
       " 'retirement': 66445,\n",
       " 'plan': 61412,\n",
       " 'participation': 59994,\n",
       " 'group': 39186,\n",
       " 'health': 40485,\n",
       " 'life': 49238,\n",
       " 'insurance': 43966,\n",
       " 'status': 72658,\n",
       " 'matters': 51858,\n",
       " 'planetary': 61420,\n",
       " 'queen': 64163,\n",
       " 'kingston': 47234,\n",
       " 'graydon': 38992,\n",
       " 'saundrsg': 68596,\n",
       " 'qucdn': 64157,\n",
       " 'queensu': 64167,\n",
       " 'ca': 22822,\n",
       " 'ussr': 79136,\n",
       " 'reached': 65124,\n",
       " 'moon': 54374,\n",
       " 'dxb105': 31776,\n",
       " '734155421': 10756,\n",
       " 'aries': 17484,\n",
       " '1993apr7': 3627,\n",
       " '124724': 1808,\n",
       " '22534': 5163,\n",
       " 'yang': 84282,\n",
       " 'earlham': 32008,\n",
       " '734495289': 10763,\n",
       " 'virgo': 80353,\n",
       " '1993apr12': 3607,\n",
       " '161742': 2691,\n",
       " '22647': 5184,\n",
       " '93107': 12658,\n",
       " '144339saundrsg': 2262,\n",
       " '1993apr18': 3613,\n",
       " '091051': 780,\n",
       " '14496': 2277,\n",
       " 'ke4zv': 46813,\n",
       " '38': 7052,\n",
       " 'gary': 37574,\n",
       " 'coffman': 25442,\n",
       " 'says': 68639,\n",
       " 'turning': 77318,\n",
       " 'moonbase': 54375,\n",
       " 'ought': 59072,\n",
       " 'post': 62044,\n",
       " 'hundred': 41971,\n",
       " 'odd': 58063,\n",
       " 'posts': 62078,\n",
       " 'go': 38528,\n",
       " 'real': 65173,\n",
       " 'base': 19301,\n",
       " 'economic': 32183,\n",
       " 'someone': 71524,\n",
       " 'industry': 43450,\n",
       " 'presumeably': 62514,\n",
       " 'much': 55052,\n",
       " 'larger': 48401,\n",
       " 'gnp': 38518,\n",
       " '_without_': 14264,\n",
       " 'simply': 70576,\n",
       " 'afford': 15542,\n",
       " 'stuff': 73223,\n",
       " 'read': 65142,\n",
       " 'right': 66807,\n",
       " 'saying': 68634,\n",
       " 'essence': 33774,\n",
       " 'economy': 32191,\n",
       " 'discretionary': 30327,\n",
       " 'funds': 37037,\n",
       " 'waste': 81442,\n",
       " 'lunar': 50214,\n",
       " 'facility': 34865,\n",
       " 'certainly': 23897,\n",
       " 'partially': 59987,\n",
       " 'apollo': 17088,\n",
       " 'colonies': 25569,\n",
       " 'require': 66178,\n",
       " 'continuing': 26532,\n",
       " 'commercial': 25714,\n",
       " 'rather': 64858,\n",
       " 'money': 54276,\n",
       " 'why': 82054,\n",
       " 'approach': 17228,\n",
       " 'assuming': 17922,\n",
       " 'won': 82530,\n",
       " 'makes': 51247,\n",
       " 'profit': 62811,\n",
       " 'actually': 15140,\n",
       " 'gives': 38255,\n",
       " 'leads': 48669,\n",
       " 'spend': 71927,\n",
       " 'gosh': 38728,\n",
       " 'wow': 82687,\n",
       " 'profitable': 62813,\n",
       " 'conceivable': 26027,\n",
       " 'luna': 50212,\n",
       " 'purpose': 63476,\n",
       " 'possible': 62039,\n",
       " 'most': 54506,\n",
       " 'likely': 49299,\n",
       " 'several': 69748,\n",
       " 'bases': 19319,\n",
       " 'predicated': 62335,\n",
       " 'funding': 37035,\n",
       " 'levels': 48977,\n",
       " 'little': 49516,\n",
       " 'different': 30011,\n",
       " 'antarctic': 16863,\n",
       " 'put': 63511,\n",
       " '200': 4644,\n",
       " 'million': 53403,\n",
       " 'use': 79076,\n",
       " 'grad': 38858,\n",
       " 'students': 73210,\n",
       " '_run_': 14131,\n",
       " 'hardly': 40162,\n",
       " 'couple': 27004,\n",
       " 'centuries': 23868,\n",
       " 'before': 19708,\n",
       " 'commerical': 25719,\n",
       " 'scst83': 69103,\n",
       " 'csc': 27568,\n",
       " 'liv': 49528,\n",
       " 'ac': 14807,\n",
       " 'uk': 77984,\n",
       " 'mr': 54762,\n",
       " 'smith': 71169,\n",
       " 'telephone': 75148,\n",
       " 'audio': 18226,\n",
       " '300': 6467,\n",
       " '3000': 6468,\n",
       " 'hz': 42179,\n",
       " 'liverpool': 49536,\n",
       " '47': 8030,\n",
       " 'goyt': 38788,\n",
       " 'passband': 60049,\n",
       " '30hz': 6548,\n",
       " '4khz': 8335,\n",
       " 'implement': 43055,\n",
       " 'backward': 18966,\n",
       " 'compatable': 25826,\n",
       " 'every': 34050,\n",
       " 'effecent': 32382,\n",
       " 'mix': 53734,\n",
       " 'electrical': 32648,\n",
       " 'effecency': 32381,\n",
       " ...}"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотреть на получившийся словарь\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RUebd2PA-b5I",
    "outputId": "9e574dd8-0c7f-404c-b725-82a6b5a252b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# по умолчанию вся пунктуция удаляется\n",
    "'.' in vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRe504lhyfkc"
   },
   "source": [
    "### scipy.sparse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kplulVmobuMw"
   },
   "source": [
    "Результатом метода ***transform*** будет разреженная матрица - объект  `csr_matrix`.    \n",
    "Такие объекты оптимизируют работу с разреженными данными (в памяти хранятся **только ненулевые значения**). \n",
    "+ (+) занимает маньше места в памяти, чем те же данные в другом формате (например `pd.DataFrame` или `numpy.ndarray`)\n",
    "+ (+) модели учатся быстрее, чем на тех же данных в другом формате \n",
    "+ (-) не все модели из `sklearn` работают с разреженными данными\n",
    "+ (-) нельзя так же быстро и легко посмотреть названия признаков как в `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DEWR5nGgUid2",
    "outputId": "edc7912d-f87e-4ff7-ab09-9672083c0065"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 158,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KvzX9kYgUlQV",
    "outputId": "ab51ba90-981f-426b-a1bf-7cf5c5d50299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 448 ms, sys: 2.46 s, total: 2.91 s\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# можно преобразовать в неразреженный вид например так (может занять довольно много времени для большой матрицы)\n",
    "X_train_array = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3P7FZIe4doFd",
    "outputId": "e1542e90-d5fa-45e9-9caa-94bbad6838cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGCnpr0UeDfE"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "VaEi0ywLd_dN",
    "outputId": "a3145156-9081-4095-94d1-9a55c4911736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.01 s, sys: 34.9 ms, total: 8.05 s\n",
      "Wall time: 8.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, df_train.target) # быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "9usddByFRdiM",
    "outputId": "c6caaff8-8b3e-477a-d0f0-04338f2a1d9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.782     0.771     0.776       144\n",
      "           1      0.648     0.726     0.685       175\n",
      "           2      0.639     0.819     0.718       177\n",
      "           3      0.565     0.661     0.609       177\n",
      "           4      0.772     0.741     0.757       174\n",
      "           5      0.828     0.809     0.818       178\n",
      "           6      0.690     0.847     0.760       176\n",
      "           7      0.844     0.792     0.817       178\n",
      "           8      0.866     0.933     0.898       180\n",
      "           9      0.863     0.878     0.871       180\n",
      "          10      0.913     0.933     0.923       180\n",
      "          11      0.877     0.961     0.917       178\n",
      "          12      0.777     0.492     0.602       177\n",
      "          13      0.908     0.719     0.803       178\n",
      "          14      0.893     0.888     0.890       178\n",
      "          15      0.702     0.917     0.795       180\n",
      "          16      0.921     0.921     0.921       164\n",
      "          17      0.936     0.947     0.941       169\n",
      "          18      0.919     0.655     0.765       139\n",
      "          19      0.841     0.327     0.471       113\n",
      "\n",
      "    accuracy                          0.797      3395\n",
      "   macro avg      0.809     0.787     0.787      3395\n",
      "weighted avg      0.807     0.797     0.793      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "OzKo4bBVeS5u",
    "outputId": "45fbe7a4-4245-4647-cc0b-3498cc841e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 1.51 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "rf.fit(X_train_array, df_train.target) # ~ в 10 раз дольше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "3lCgSOTyRr7F",
    "outputId": "fb4d5b13-80fd-410d-ab4c-d097295254fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.782     0.771     0.776       144\n",
      "           1      0.648     0.726     0.685       175\n",
      "           2      0.639     0.819     0.718       177\n",
      "           3      0.565     0.661     0.609       177\n",
      "           4      0.772     0.741     0.757       174\n",
      "           5      0.828     0.809     0.818       178\n",
      "           6      0.690     0.847     0.760       176\n",
      "           7      0.844     0.792     0.817       178\n",
      "           8      0.866     0.933     0.898       180\n",
      "           9      0.863     0.878     0.871       180\n",
      "          10      0.913     0.933     0.923       180\n",
      "          11      0.877     0.961     0.917       178\n",
      "          12      0.777     0.492     0.602       177\n",
      "          13      0.908     0.719     0.803       178\n",
      "          14      0.893     0.888     0.890       178\n",
      "          15      0.702     0.917     0.795       180\n",
      "          16      0.921     0.921     0.921       164\n",
      "          17      0.936     0.947     0.941       169\n",
      "          18      0.919     0.655     0.765       139\n",
      "          19      0.841     0.327     0.471       113\n",
      "\n",
      "    accuracy                          0.797      3395\n",
      "   macro avg      0.809     0.787     0.787      3395\n",
      "weighted avg      0.807     0.797     0.793      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# качество абсолютно одинаковое, т.к. данные одни и те же \n",
    "y_pred = rf.predict(X_test.toarray())\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c72pW-ZDv_DV"
   },
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R6GM9aLLyHBM"
   },
   "source": [
    "Помимо отдельных слов при векторизации можно использовать н-граммы. \n",
    "+ (+) возможно качество модели будет лучше, тк информации больше\n",
    "+ (-) словарь, а с ним и матрица признаков становится сильно больше "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZDRRJ7yOyEJ"
   },
   "outputs": [],
   "source": [
    "# отдельные слова, биграммы, триграммы\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "QkH9J3i9Pu0G",
    "outputId": "6f0753bf-bea2-419c-c625-5f20fd903ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 880 ms, total: 17.1 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_ngram = ngram_vectorizer.fit_transform(df_train.text) \n",
    "X_test_ngram = ngram_vectorizer.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MbUaZEtsQfTt",
    "outputId": "f0e5777b-ad15-4ec3-8d20-83d6ca0ffc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 1816567 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря: %s элементов' % X_train_ngram.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "1sG9oH2MUd3U",
    "outputId": "970a3319-8d10-41e6-dcaf-6e1bd330a378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 27.6 ms, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_ngram, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "AXbD5pQ1Un7n",
    "outputId": "79d18711-c0e9-4093-a6e0-4d3c7728ad10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.949     0.771     0.851       144\n",
      "           1      0.534     0.754     0.626       175\n",
      "           2      0.623     0.729     0.672       177\n",
      "           3      0.595     0.621     0.608       177\n",
      "           4      0.809     0.730     0.767       174\n",
      "           5      0.819     0.736     0.775       178\n",
      "           6      0.594     0.881     0.709       176\n",
      "           7      0.841     0.831     0.836       178\n",
      "           8      0.827     0.906     0.865       180\n",
      "           9      0.825     0.839     0.832       180\n",
      "          10      0.897     0.917     0.907       180\n",
      "          11      0.933     0.938     0.936       178\n",
      "          12      0.778     0.554     0.647       177\n",
      "          13      0.913     0.708     0.797       178\n",
      "          14      0.968     0.860     0.911       178\n",
      "          15      0.688     0.906     0.782       180\n",
      "          16      0.933     0.939     0.936       164\n",
      "          17      0.993     0.899     0.944       169\n",
      "          18      0.962     0.727     0.828       139\n",
      "          19      0.850     0.451     0.590       113\n",
      "\n",
      "    accuracy                          0.791      3395\n",
      "   macro avg      0.817     0.785     0.791      3395\n",
      "weighted avg      0.812     0.791     0.793      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# действительно, качество стало получше\n",
    "y_pred = rf.predict(X_test_ngram)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLKGfjjCyghZ"
   },
   "source": [
    "### Уменьшить размер словаря"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-ae3WwfYcgz"
   },
   "source": [
    "Параметры\n",
    "+ **min_df: *float in range [0.0, 1.0] or int, default=1*** - при построении словаря не учитывать элементы, которые встречаются в количестве документов меньше заданного порога.     \n",
    "Полезно, если мы не хотим учитывать в словаре всякие странные слова (с опечатками, имена собственные,и т.д.), которые встречаются в очень малом количестве документов и из-за этого неинформативны для модели (почти константный признак, состоящий в основном из 0.) \n",
    "+ **max_df: *float in range [0.0, 1.0] or int, default=1.0*** - при построении словаря не учитывать элементы, которые встречаются в количестве документов больше заданного порога.     \n",
    "Полезно, если мы не хотим учитывать в словаре очень частотные слова (союзы, местоимения), которые встречаются во всех или почти во всех документах и из-за этого неинформативны для модели (почти константный признак). \n",
    "+ **max_features: *int, default=None*** - эксплицитно ограничить размер словаря заданным числом, в словарь войдет заданное число самых частотных элементов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-NQFKBLTVZR"
   },
   "source": [
    "#### min_df & max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V62RqtFIhPyb"
   },
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=5, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tr3x8idpLnvv"
   },
   "outputs": [],
   "source": [
    "X_train_ngram_trunc = ngram_vectorizer.fit_transform(df_train.text)\n",
    "X_test_ngram_trunc = ngram_vectorizer.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hKdup6CtHJlS",
    "outputId": "f3a98524-bb75-415a-a804-d72a99883f86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря до: 1816567 элементов\n",
      "Размер словаря с ограничениями min_df и max_df: 80469 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря до: %s элементов' % X_train_ngram.shape[1])\n",
    "print('Размер словаря с ограничениями min_df и max_df: %s элементов' % X_train_ngram_trunc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "lKu6AMH8S4MP",
    "outputId": "f10097a0-5fb2-460b-860a-0e251c42bd8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.3 s, sys: 9.91 ms, total: 8.31 s\n",
      "Wall time: 8.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_ngram_trunc, df_train.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "vbgzNnX3TIjV",
    "outputId": "d84bc6bd-6da4-46a0-8625-158ac67c9a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.931     0.847     0.887       144\n",
      "           1      0.702     0.714     0.708       175\n",
      "           2      0.603     0.842     0.703       177\n",
      "           3      0.559     0.593     0.575       177\n",
      "           4      0.764     0.764     0.764       174\n",
      "           5      0.812     0.803     0.808       178\n",
      "           6      0.748     0.858     0.799       176\n",
      "           7      0.817     0.826     0.821       178\n",
      "           8      0.885     0.894     0.890       180\n",
      "           9      0.817     0.867     0.841       180\n",
      "          10      0.874     0.883     0.878       180\n",
      "          11      0.919     0.955     0.937       178\n",
      "          12      0.723     0.559     0.631       177\n",
      "          13      0.895     0.719     0.798       178\n",
      "          14      0.910     0.910     0.910       178\n",
      "          15      0.744     0.922     0.824       180\n",
      "          16      0.928     0.939     0.933       164\n",
      "          17      0.964     0.964     0.964       169\n",
      "          18      0.914     0.691     0.787       139\n",
      "          19      0.862     0.442     0.585       113\n",
      "\n",
      "    accuracy                          0.807      3395\n",
      "   macro avg      0.819     0.800     0.802      3395\n",
      "weighted avg      0.815     0.807     0.805      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# качество не пострадало, даже улучшилось \n",
    "# обучается намного быстрее\n",
    "y_pred = rf.predict(X_test_ngram_trunc)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwu7HGWBTRz8"
   },
   "source": [
    "#### max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iTDrwaR6HJ2K"
   },
   "outputs": [],
   "source": [
    "ngram_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vlvSAk-tSCFj"
   },
   "outputs": [],
   "source": [
    "X_train_ngram_trunc = ngram_vectorizer.fit_transform(df_train.text)\n",
    "X_test_ngram_trunc = ngram_vectorizer.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Enq5V1KzSDV1",
    "outputId": "6b6b6570-76df-41d7-cbe3-8db3cae8b74a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря до: 1816567 элементов\n",
      "Размер словаря с ограничениями max_features: 10000 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря до: %s элементов' % X_train_ngram.shape[1])\n",
    "print('Размер словаря с ограничениями max_features: %s элементов' % X_train_ngram_trunc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Q2wohgy3S5DS",
    "outputId": "2b9b79fc-5036-45ec-b6a6-1c04ddfcb659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 5.97 ms, total: 6.27 s\n",
      "Wall time: 6.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_ngram_trunc, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "RCPmiraOT1CM",
    "outputId": "b712b750-3d56-4a2a-832c-163132eaa877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.869     0.785     0.825       144\n",
      "           1      0.638     0.646     0.642       175\n",
      "           2      0.652     0.751     0.698       177\n",
      "           3      0.522     0.605     0.560       177\n",
      "           4      0.721     0.713     0.717       174\n",
      "           5      0.802     0.775     0.789       178\n",
      "           6      0.717     0.835     0.772       176\n",
      "           7      0.787     0.770     0.778       178\n",
      "           8      0.886     0.906     0.896       180\n",
      "           9      0.727     0.872     0.793       180\n",
      "          10      0.915     0.839     0.875       180\n",
      "          11      0.902     0.933     0.917       178\n",
      "          12      0.611     0.514     0.558       177\n",
      "          13      0.840     0.736     0.784       178\n",
      "          14      0.875     0.865     0.870       178\n",
      "          15      0.736     0.900     0.810       180\n",
      "          16      0.890     0.933     0.911       164\n",
      "          17      0.934     0.923     0.929       169\n",
      "          18      0.872     0.683     0.766       139\n",
      "          19      0.793     0.407     0.538       113\n",
      "\n",
      "    accuracy                          0.777      3395\n",
      "   macro avg      0.784     0.770     0.771      3395\n",
      "weighted avg      0.782     0.777     0.775      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обучилось быстро, но качество пострадало\n",
    "y_pred = rf.predict(X_test_ngram_trunc)\n",
    "print(classification_report(df_test.target, y_pred, digits=3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Qk7PJ0iT_Fk"
   },
   "source": [
    "#### Предобработка\n",
    "+ Лемматизация или стемминг (меньше разных слов = меньше словарь)\n",
    "+ Стоп-слова \n",
    "+ И то, и друое можно сделать сразу в объекте векторизатора, ередав нужные параметры\n",
    "    + **preprocessor: *callable, default=None*** - вызываемый объект, который будет делать предобработку, должен принимать на вход слвоо и возвращать его же  в обработанном виде \n",
    "    + **stop_words: *list, default=None*** - список стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6nYNba-Xsay"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "FtGT-s2LZKYS",
    "outputId": "46461e2d-b26a-425d-d432-53aa348ef7c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "eng_stop_words = stopwords.words('english')\n",
    "print(eng_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yk8MOPzKYdOF"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fbs645i6YhZb"
   },
   "outputs": [],
   "source": [
    "vectorizer_preproc = CountVectorizer(ngram_range=(1, 3), stop_words=eng_stop_words, preprocessor=lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "NB5o1K8DZ0Ug",
    "outputId": "d19ed789-7b74-4c44-94a5-af03ddc75679"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 78 ms, total: 12.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_preproc = vectorizer_preproc.fit_transform(df_train.text)\n",
    "X_test_preproc = vectorizer_preproc.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GHvTcZYdaUqn",
    "outputId": "61cf30c7-043e-432b-b7dd-1905f58144ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря до: 1816567 элементов\n",
      "Размер словаря после предобрабоки: 1607473 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря до: %s элементов' % X_train_ngram.shape[1])\n",
    "print('Размер словаря после предобрабоки: %s элементов' % X_train_preproc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "jl54QTpAaN6e",
    "outputId": "9f9a076a-21bc-4ff4-a941-78ad0538c068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 1s, sys: 24.4 ms, total: 1min 1s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_preproc, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "t_qbqHhDagMq",
    "outputId": "99a407a3-3df7-4ea3-9565-a628ab07f6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.898     0.854     0.875       144\n",
      "           1      0.525     0.783     0.628       175\n",
      "           2      0.648     0.802     0.717       177\n",
      "           3      0.645     0.718     0.679       177\n",
      "           4      0.831     0.678     0.747       174\n",
      "           5      0.856     0.770     0.811       178\n",
      "           6      0.592     0.875     0.706       176\n",
      "           7      0.891     0.826     0.857       178\n",
      "           8      0.908     0.928     0.918       180\n",
      "           9      0.824     0.856     0.839       180\n",
      "          10      0.856     0.894     0.875       180\n",
      "          11      0.965     0.927     0.946       178\n",
      "          12      0.827     0.514     0.634       177\n",
      "          13      0.927     0.713     0.806       178\n",
      "          14      0.940     0.876     0.907       178\n",
      "          15      0.753     0.900     0.820       180\n",
      "          16      0.956     0.927     0.941       164\n",
      "          17      0.969     0.923     0.945       169\n",
      "          18      0.955     0.755     0.843       139\n",
      "          19      0.909     0.531     0.670       113\n",
      "\n",
      "    accuracy                          0.807      3395\n",
      "   macro avg      0.834     0.803     0.808      3395\n",
      "weighted avg      0.830     0.807     0.810      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_preproc)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpedriMoKuEg"
   },
   "source": [
    "### Char "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "266uquz0jxpt"
   },
   "source": [
    "+ В качестве элемента словаря можно взять не целые слова, а символы/символьные н-граммы, за это отвечает параметр **analyzer**\n",
    "+ **analyzer: *{‘word’, ‘char’, ‘char_wb’} or callable, default=’word’***\n",
    "    + word - слова\n",
    "    + char - символы\n",
    "    + char_wb -  символы, но н-граммы создаются только в пределах границ слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc-nX4_FONnf"
   },
   "outputs": [],
   "source": [
    "char_vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "_h9MEdwCQrvi",
    "outputId": "5011bbd7-ab9b-47f3-8289-6b7beaa256cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.6 s, sys: 449 ms, total: 59.1 s\n",
      "Wall time: 59.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_char = char_vectorizer.fit_transform(df_train.text)\n",
    "X_test_char = char_vectorizer.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S6ZT3t1xR8kx",
    "outputId": "e779f670-43f1-40b6-8ce1-bee7aa3fbc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 1686613 элементов\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря: %s элементов' % X_train_char.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "aRkIoRc4SONq",
    "outputId": "dd25fd14-b474-479e-cab9-dffee5eac341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.3 s, sys: 40.8 ms, total: 55.3 s\n",
      "Wall time: 55.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_char, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "D3ZI0w4eSz_8",
    "outputId": "6b495643-c09e-4293-968c-5ece4d66eadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.874     0.771     0.819       144\n",
      "           1      0.620     0.634     0.627       175\n",
      "           2      0.586     0.791     0.673       177\n",
      "           3      0.521     0.571     0.544       177\n",
      "           4      0.693     0.701     0.697       174\n",
      "           5      0.825     0.792     0.808       178\n",
      "           6      0.700     0.824     0.757       176\n",
      "           7      0.736     0.753     0.744       178\n",
      "           8      0.870     0.894     0.882       180\n",
      "           9      0.770     0.856     0.811       180\n",
      "          10      0.894     0.889     0.891       180\n",
      "          11      0.884     0.938     0.910       178\n",
      "          12      0.649     0.480     0.552       177\n",
      "          13      0.853     0.685     0.760       178\n",
      "          14      0.846     0.865     0.856       178\n",
      "          15      0.706     0.867     0.778       180\n",
      "          16      0.887     0.909     0.898       164\n",
      "          17      0.940     0.929     0.935       169\n",
      "          18      0.925     0.619     0.741       139\n",
      "          19      0.758     0.416     0.537       113\n",
      "\n",
      "    accuracy                          0.767      3395\n",
      "   macro avg      0.777     0.759     0.761      3395\n",
      "weighted avg      0.774     0.767     0.764      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_char)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1lotS9jTgAxI"
   },
   "source": [
    "## 2. Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-7hIUgQDvAw_"
   },
   "source": [
    "**Term frequency - inverted document frequency**     \n",
    "Формула:\n",
    "\n",
    "![](https://miro.medium.com/max/1200/1*V9ac4hLVyms79jl65Ym_Bw.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gX9OKFPvgIJD"
   },
   "source": [
    "+ **TF** - оценивает важность слова для конкретного документа, (чем чаще встречается это слово в документе, тем больше значение)\n",
    "+ **IDF** - инверсия частоты, с которой некоторое слово встречается в документах коллекции. Чем чаще слово встречается во всей коллекции, тем меньше значение IDF. \n",
    "+ В итоге большой вес получают специфичные для конкретного документа слова (часто встречаются в документе, редко встречаются в остальной коллекции). \n",
    "+ В отличие от CountVectorizer учиывает не только информацию о конкретном документе, но и о всей коллеции в целом. \n",
    "+ Можно делать все те же вещи, что и c CountVectorizer (параметры одинаковые). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8QD7Uzf5fv1"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdIGXBWX4ucV"
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 4), min_df=5, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KBdA_1mi5P1o",
    "outputId": "31c6a0c0-fef0-439e-a62e-d2d845670662"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 s, sys: 462 ms, total: 26.3 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train.text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "56NJ_LrZ7L_n",
    "outputId": "db02bc80-c49c-424f-9a94-ffc03f9ffed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.46 s, sys: 12.9 ms, total: 9.48 s\n",
      "Wall time: 9.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 192,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train_tfidf, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "ndpAJ22M7ktK",
    "outputId": "f866ed1b-90b4-4ced-9513-44ca845fe5b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.944     0.819     0.877       144\n",
      "           1      0.688     0.669     0.678       175\n",
      "           2      0.637     0.814     0.715       177\n",
      "           3      0.551     0.644     0.594       177\n",
      "           4      0.808     0.724     0.764       174\n",
      "           5      0.763     0.798     0.780       178\n",
      "           6      0.733     0.875     0.798       176\n",
      "           7      0.835     0.826     0.831       178\n",
      "           8      0.878     0.917     0.897       180\n",
      "           9      0.827     0.850     0.838       180\n",
      "          10      0.878     0.917     0.897       180\n",
      "          11      0.938     0.938     0.938       178\n",
      "          12      0.653     0.542     0.593       177\n",
      "          13      0.896     0.775     0.831       178\n",
      "          14      0.873     0.888     0.880       178\n",
      "          15      0.729     0.911     0.810       180\n",
      "          16      0.905     0.933     0.919       164\n",
      "          17      0.963     0.929     0.946       169\n",
      "          18      0.896     0.683     0.776       139\n",
      "          19      0.909     0.442     0.595       113\n",
      "\n",
      "    accuracy                          0.802      3395\n",
      "   macro avg      0.815     0.795     0.798      3395\n",
      "weighted avg      0.811     0.802     0.801      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test_tfidf)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1wfJ7Jkfcmm"
   },
   "source": [
    "## Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEztzLoHS5fb"
   },
   "outputs": [],
   "source": [
    "# вытащить названия признаков из векторизатора\n",
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "0rbOx727TlFP",
    "outputId": "f47c28b3-7c1e-4d56-b322-bd0aa6332377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zurich',\n",
       " 'zurich ch',\n",
       " 'zurich ch lines',\n",
       " 'zv',\n",
       " 'zx',\n",
       " 'zx 10',\n",
       " 'zx 11',\n",
       " 'zx 11 needs',\n",
       " 'zx 11 needs name',\n",
       " 'zz']"
      ]
     },
     "execution_count": 225,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0j3zt_CTsZs"
   },
   "outputs": [],
   "source": [
    "sorted_features = sorted(zip(feature_names, rf.feature_importances_), reverse=True, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "Bx1v0nk-VNEB",
    "outputId": "b7f0c815-1358-4ca4-94c1-316e29a0d1e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to convince you', 0.0011523099558869829),\n",
       " ('to convince', 0.001021915483592786),\n",
       " ('to you if you', 0.0006353750685443431),\n",
       " ('who fled', 0.0005633017530330256),\n",
       " ('in bosnia', 0.00045975963770404475),\n",
       " ('try something', 0.00045783278099319),\n",
       " ('vax2 winona msus edu', 0.0004098137964457366),\n",
       " ('we are talking', 0.000350556213973507),\n",
       " ('worry about it', 0.00033842076932229237),\n",
       " ('would be the best', 0.0003136096781982108),\n",
       " ('other factors', 0.0003053102655309554),\n",
       " ('who came', 0.00028616224774834117),\n",
       " ('this can', 0.00028447286981950264),\n",
       " ('tri university meson facility', 0.0002791345825931791),\n",
       " ('you are interested in', 0.00027454950140595524),\n",
       " ('they repress', 0.0002741098797272048),\n",
       " ('williams', 0.0002723954724529015),\n",
       " ('they don believe', 0.0002678227006612262),\n",
       " ('situations like', 0.00025992336079841736),\n",
       " ('they certainly', 0.00025937649824552575),\n",
       " ('if am', 0.00024976056608331707),\n",
       " ('to 25', 0.00024608005201786633),\n",
       " ('today are', 0.00024470030723171325),\n",
       " ('with number of', 0.00024034189481464323),\n",
       " ('b5', 0.00023807863826512973),\n",
       " ('then one', 0.00023474822653947482),\n",
       " ('people aren', 0.00022466896918313414),\n",
       " ('why would the stove', 0.00021746776123553562),\n",
       " ('this point in', 0.00021639830961048978),\n",
       " ('very much appreciated', 0.00021585252712357362)]"
      ]
     },
     "execution_count": 233,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_features[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjKwekd17oDG"
   },
   "source": [
    "## PoS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXhm0XYY7rz3"
   },
   "source": [
    "+ векторизировать имеет смысл не только сами слова, но и разную другую информацию о них\n",
    "+ например части речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqwZo6_39QUj"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xepPPtP7FoG7",
    "outputId": "3de5acf5-41c1-4742-ca4e-cd02cffa06b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('cats', 'NNS'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 195,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize('I love cats!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-nXRJeys8Lj4"
   },
   "outputs": [],
   "source": [
    "def get_pos_str(text):\n",
    "    pos = ' '.join([an[1] for an in pos_tag(word_tokenize(text)) if an[1] != '.'])\n",
    "    return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qP6fIxAtF5VR",
    "outputId": "8e670240-5ec4-4b4c-ef88-8bfa05c8f358"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRP VBP NNS'"
      ]
     },
     "execution_count": 197,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos_str('I love cats!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "szdazrOzGkCO",
    "outputId": "6896bb07-3bc2-4d80-eca8-9fe2d22f6a51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 164 ms, total: 2min 42s\n",
      "Wall time: 2min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train['pos'] = [get_pos_str(text) for text in df_train.text]\n",
    "df_test['pos'] = [get_pos_str(text) for text in df_test.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TR_AhH4eGbja"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "12_8sDavHGRY",
    "outputId": "945ac052-bb3b-4414-bfbd-20955f870c43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 4.98 ms, total: 1.36 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_pos = vectorizer.fit_transform(df_train.pos)\n",
    "X_test_pos = vectorizer.transform(df_test.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "jsYB-PjgKSk9",
    "outputId": "55116cfc-626e-4ee0-816c-ec619594d9ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cc': 0,\n",
       " 'cd': 1,\n",
       " 'dt': 2,\n",
       " 'ex': 3,\n",
       " 'fw': 4,\n",
       " 'in': 5,\n",
       " 'jj': 6,\n",
       " 'jjr': 7,\n",
       " 'jjs': 8,\n",
       " 'ls': 9,\n",
       " 'md': 10,\n",
       " 'nn': 11,\n",
       " 'nnp': 12,\n",
       " 'nnps': 13,\n",
       " 'nns': 14,\n",
       " 'pdt': 15,\n",
       " 'pos': 16,\n",
       " 'prp': 17,\n",
       " 'rb': 18,\n",
       " 'rbr': 19,\n",
       " 'rbs': 20,\n",
       " 'rp': 21,\n",
       " 'sym': 22,\n",
       " 'to': 23,\n",
       " 'uh': 24,\n",
       " 'vb': 25,\n",
       " 'vbd': 26,\n",
       " 'vbg': 27,\n",
       " 'vbn': 28,\n",
       " 'vbp': 29,\n",
       " 'vbz': 30,\n",
       " 'wdt': 31,\n",
       " 'wp': 32,\n",
       " 'wrb': 33}"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phPfFiMSJGav"
   },
   "source": [
    "Обучаться только на векторах частей речи скорее всего будет неэффективно, поэтому давайте присоединим векторы частей речи к векторам слов, полученным ранее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FSgF5rqJb12"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yvmadCV0LODR"
   },
   "outputs": [],
   "source": [
    "X_train = hstack((X_train_pos, X_train_tfidf))\n",
    "X_test = hstack((X_test_pos, X_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "YDAWlYlAMS-4",
    "outputId": "ac9eaee9-1bf2-4629-990d-c3da8f9d24aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.5 s, sys: 5.99 ms, total: 9.51 s\n",
      "Wall time: 9.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 215,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "3EG_us0EMfKq",
    "outputId": "0eb5402e-2326-4394-8699-eb16370c3e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.930     0.826     0.875       144\n",
      "           1      0.636     0.760     0.693       175\n",
      "           2      0.695     0.785     0.737       177\n",
      "           3      0.599     0.667     0.631       177\n",
      "           4      0.805     0.713     0.756       174\n",
      "           5      0.841     0.775     0.807       178\n",
      "           6      0.699     0.869     0.775       176\n",
      "           7      0.814     0.837     0.825       178\n",
      "           8      0.864     0.883     0.874       180\n",
      "           9      0.790     0.856     0.821       180\n",
      "          10      0.894     0.889     0.891       180\n",
      "          11      0.918     0.944     0.931       178\n",
      "          12      0.680     0.588     0.630       177\n",
      "          13      0.917     0.747     0.824       178\n",
      "          14      0.872     0.876     0.874       178\n",
      "          15      0.716     0.911     0.802       180\n",
      "          16      0.942     0.896     0.919       164\n",
      "          17      0.969     0.935     0.952       169\n",
      "          18      0.892     0.770     0.826       139\n",
      "          19      0.855     0.416     0.560       113\n",
      "\n",
      "    accuracy                          0.804      3395\n",
      "   macro avg      0.816     0.797     0.800      3395\n",
      "weighted avg      0.813     0.804     0.803      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2kbBfymNpRW"
   },
   "source": [
    "**Задание**\n",
    "+ вывести наиболее важные признаки этой модели "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "08.06_natural_language1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
