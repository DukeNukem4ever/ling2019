{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rm0hokW1ctGm"
   },
   "source": [
    "## Домашнее задание 8 (бонусное). Обработка текстов. \n",
    "Дедлайн: 24.06.2020 23:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UbzklKqIVf-h"
   },
   "source": [
    "Ваша задача - определить тональность твита (0 - отрицательная, 4 - положительная) по его тексту.       \n",
    "Ваша модель должна превзойти указанные бейзлайны (метрика качества - ***accuracy_score***) на тестовой выборке (***df_test***).     \n",
    "Чем больше бейзлайнов вы пройдете, тем выше будет ваша оценка.       \n",
    "Использовать можно любые модели и любые способы получения признаков. \n",
    "\n",
    "+ **!** Необходимо сделать результаты воспроизводимыми (фиксировать random_state)\n",
    "+ **!** Для обучения можно использовать только ***df_train***. \n",
    "+ **!** Менять разбиение на  ***df_train*** и ***df_test*** нельзя.\n",
    "\n",
    "**Оценивание (всего 10 баллов)**: \n",
    "+ Бейзлайн 1 0.73875 - 4 балла\n",
    "+ Бейзлайн 2 0.75325 - 6 баллов\n",
    "+ Бейзлайн 3 0.7635 - 8 баллов \n",
    "+ Бейзлайн 4 0.777 - 10 баллов\n",
    "\n",
    "**Возможные направления улучшения качества**\n",
    "+ улучшение предобработки (сейчас ее по сути нет)\n",
    "+ подбор более удачной модели\n",
    "+ подбор параметров модели \n",
    "+ feature engineering\n",
    "+ feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KrLxz-wZcmp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix, hstack\n",
    "from scipy.sparse.csr import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twi_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Tue Jun 02 02:59:24 PDT 2009</td>\n",
       "      <td>@JackAllTimeLow hope it went good! i couldnt m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jun 06 00:25:20 PDT 2009</td>\n",
       "      <td>@SDI8732 Idk how to do it!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jun 05 12:07:23 PDT 2009</td>\n",
       "      <td>@kmwindmill is here ! woop woop , would be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jun 01 14:55:06 PDT 2009</td>\n",
       "      <td>@Daydreamer1984 He explains the tailer better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sat Jun 20 15:39:44 PDT 2009</td>\n",
       "      <td>still trying to get a pic on this twitter thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Mon Jun 01 17:05:44 PDT 2009</td>\n",
       "      <td>personally, i'm pretty upset ian left the cab....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Fri May 29 15:32:09 PDT 2009</td>\n",
       "      <td>Dance meeting sitting next to deb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Sun May 31 08:07:19 PDT 2009</td>\n",
       "      <td>@thespyglass ha... funnier the way you did it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon Jun 01 18:12:27 PDT 2009</td>\n",
       "      <td>wooh, i love @mileycyruss! i actuallly just sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Sat May 30 09:17:18 PDT 2009</td>\n",
       "      <td>@EdinMarathonBot R-4_it is great  I'm staying ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                          date  \\\n",
       "0       4  Tue Jun 02 02:59:24 PDT 2009   \n",
       "1       0  Sat Jun 06 00:25:20 PDT 2009   \n",
       "2       0  Fri Jun 05 12:07:23 PDT 2009   \n",
       "3       4  Mon Jun 01 14:55:06 PDT 2009   \n",
       "4       0  Sat Jun 20 15:39:44 PDT 2009   \n",
       "5       0  Mon Jun 01 17:05:44 PDT 2009   \n",
       "6       4  Fri May 29 15:32:09 PDT 2009   \n",
       "7       4  Sun May 31 08:07:19 PDT 2009   \n",
       "8       4  Mon Jun 01 18:12:27 PDT 2009   \n",
       "9       4  Sat May 30 09:17:18 PDT 2009   \n",
       "\n",
       "                                                text  \n",
       "0  @JackAllTimeLow hope it went good! i couldnt m...  \n",
       "1                      @SDI8732 Idk how to do it!!!   \n",
       "2  @kmwindmill is here ! woop woop , would be bet...  \n",
       "3     @Daydreamer1984 He explains the tailer better   \n",
       "4  still trying to get a pic on this twitter thin...  \n",
       "5  personally, i'm pretty upset ian left the cab....  \n",
       "6                 Dance meeting sitting next to deb   \n",
       "7  @thespyglass ha... funnier the way you did it...   \n",
       "8  wooh, i love @mileycyruss! i actuallly just sa...  \n",
       "9  @EdinMarathonBot R-4_it is great  I'm staying ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.5\n",
       "0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# баланс классов\n",
    "df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиение и пропорции обучающей и тестовой выборки менять нельзя\n",
    "SEED = 227\n",
    "np.random.seed(SEED)\n",
    "df_train, df_test = train_test_split(df, train_size=0.2, test_size=0.1, stratify=df.target, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.target\n",
    "y_test = df_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 \n",
    "Count Vectorizer по словам + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 0 ns, total: 149 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(df_train.text)\n",
    "X_test_count = count_vectorizer.transform(df_test.text)\n",
    "X_train = X_train_count\n",
    "X_test = X_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 ms, sys: 3.78 ms, total: 5.35 ms\n",
      "Wall time: 24.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.82      0.76      2000\n",
      "           4       0.78      0.66      0.72      2000\n",
      "\n",
      "    accuracy                           0.74      4000\n",
      "   macro avg       0.74      0.74      0.74      4000\n",
      "weighted avg       0.74      0.74      0.74      4000\n",
      "\n",
      "Accuracy: 0.73875\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2 \n",
    "TfidfVectorizer по словам + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 157 ms, sys: 0 ns, total: 157 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train.text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test.text)\n",
    "X_train = X_train_tfidf\n",
    "X_test = X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 131 ms, sys: 0 ns, total: 131 ms\n",
      "Wall time: 37.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76      2000\n",
      "           4       0.76      0.74      0.75      2000\n",
      "\n",
      "    accuracy                           0.75      4000\n",
      "   macro avg       0.75      0.75      0.75      4000\n",
      "weighted avg       0.75      0.75      0.75      4000\n",
      "\n",
      "Accuracy: 0.75325\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3\n",
    "TfidfVectorizer по 1-3 граммам слов + TfidfVectorizer по 3-4граммам символов + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.66 s, sys: 62.8 ms, total: 2.73 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 4))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(df_train.text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(df_test.text)\n",
    "\n",
    "tfidf_vectorizer_char = TfidfVectorizer(ngram_range=(3, 4), analyzer='char')\n",
    "X_train_tfidf_char = tfidf_vectorizer_char.fit_transform(df_train.text)\n",
    "X_test_tfidf_char = tfidf_vectorizer_char.transform(df_test.text)\n",
    "\n",
    "X_train = hstack((X_train_tfidf, X_train_tfidf_char))\n",
    "X_test = hstack((X_test_tfidf, X_test_tfidf_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 27.6 ms, total: 1.29 s\n",
      "Wall time: 322 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      2000\n",
      "           4       0.77      0.76      0.76      2000\n",
      "\n",
      "    accuracy                           0.76      4000\n",
      "   macro avg       0.76      0.76      0.76      4000\n",
      "weighted avg       0.76      0.76      0.76      4000\n",
      "\n",
      "Accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 4\n",
    "Baseline 3 + эмбединги из spacy (вектор документа = среднее векторов всех его слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz#egg=en_core_web_md==2.2.5 in /home/lena/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/lena/anaconda3/lib/python3.7/site-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.17.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (41.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.46.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/lena/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/lena/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/lena/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/lena/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/lena/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lena/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2019.9.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/lena/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /home/lena/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (7.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n",
      "CPU times: user 13.9 s, sys: 492 ms, total: 14.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python -m spacy download en_core_web_md\n",
    "import spacy \n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 67.4 ms, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_vectors = csr_matrix([nlp(twi_text).vector for twi_text in df_train.text])\n",
    "X_test_vectors = csr_matrix([nlp(twi_text).vector for twi_text in df_test.text])\n",
    "X_train = hstack((X_train_tfidf, X_train_tfidf_char, X_train_vectors))\n",
    "X_test = hstack((X_test_tfidf, X_test_tfidf_char, X_test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.74 s, sys: 128 ms, total: 6.87 s\n",
      "Wall time: 1.73 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=227, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = LogisticRegression(random_state=SEED, solver='liblinear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      2000\n",
      "           4       0.78      0.76      0.77      2000\n",
      "\n",
      "    accuracy                           0.78      4000\n",
      "   macro avg       0.78      0.78      0.78      4000\n",
      "weighted avg       0.78      0.78      0.78      4000\n",
      "\n",
      "Accuracy: 0.777\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Accuracy: {accuracy_score(y_pred, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
