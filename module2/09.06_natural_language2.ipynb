{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvyHJuUgEOS5"
   },
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXeJN8n3sk_M"
   },
   "source": [
    "В интернете есть много обученных моделей word2vec на разных копусах и для разных языков. Можно скачать и загрузить готовую модель. \n",
    "Например:\n",
    "+ [Google news (английский)](https://code.google.com/archive/p/word2vec/)\n",
    "+ [Репозиторий NLPL - много разных моделей на разных языках](http://vectors.nlpl.eu/repository/#)\n",
    "+ [Википедия на разных языках](https://wikipedia2vec.github.io/wikipedia2vec/pretrained/)\n",
    "+ [RusVectores (русский)](https://rusvectores.org/ru/models/)\n",
    "+ и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPUK5PQGtD7Y"
   },
   "source": [
    "Мы сегодня будем пользоваться самой маленькой моделью с RusVectores (**news_upos_cbow_300_2_2017** - 130 мб, около 200 тыс слов в словаре, обучалась на корпусе русскоязычных новостей).     \n",
    "Хорошая практика - обучение на корпусе с аннотированными частями речи, помогает с проблемой омонимии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPOrVL1DhAxa"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osY4-fUzhBRs"
   },
   "outputs": [],
   "source": [
    "# умеет читать сразу из архива на сайте\n",
    "# не нужно скачивать и распаковывать\n",
    "model = KeyedVectors.load_word2vec_format('https://rusvectores.org/static/models/news_upos_cbow_300_2_2017.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6yYf4_lu1Mw"
   },
   "outputs": [],
   "source": [
    "# посмотреть словарь\n",
    "model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldoyj-AfuDFw"
   },
   "outputs": [],
   "source": [
    "# посмотреть вектор слова\n",
    "# model.wv['скоро_ADV']\n",
    "model.get_vector('скоро_ADV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mHsivwRQsAU"
   },
   "source": [
    "## Операции с векторами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNAoyCbHRt2T"
   },
   "source": [
    "Мера косинусной близости (угол)          \n",
    "\n",
    "+ Чем чаще слова встречаются в одинаковых контекстах, тем больше значение. \n",
    "![](https://erikbern.com/assets/2015/09/vector-model1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8PhTBONWQs3"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wk-57I7zVNab"
   },
   "outputs": [],
   "source": [
    "model.similarity('скоро_ADV', 'грустно_ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbalIzMaQyid"
   },
   "outputs": [],
   "source": [
    "# контекстные синонимы\n",
    "model.similarity('скоро_ADV', 'быстро_ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBkbG21-Vvv2"
   },
   "outputs": [],
   "source": [
    "# антонимы\n",
    "model.similarity('быстро_ADV', 'медленно_ADV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GZMZBOuRx3M"
   },
   "source": [
    "Найти самые близкие слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOe3PonmQy5t"
   },
   "outputs": [],
   "source": [
    "# из всего словаря\n",
    "model.most_similar('быстро_ADV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rooI2CYqTa0F"
   },
   "outputs": [],
   "source": [
    "# самое близкое слово из списка\n",
    "model.most_similar_to_given('быстро_ADV', ['красиво_ADV', 'быстрота_NOUN', 'быстрый_ADJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnzNWd9TeoX9"
   },
   "source": [
    "Самые непохожие слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmjBybCXeaos"
   },
   "outputs": [],
   "source": [
    "model.most_similar(negative=['красивый_ADJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdsan8zpS27R"
   },
   "source": [
    "Какое слово лишнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQpf4HfpRCaU"
   },
   "outputs": [],
   "source": [
    "model.doesnt_match(['кошка_NOUN', 'собака_NOUN', 'голубь_NOUN', 'трамвай_NOUN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRvyjWmGZJRh"
   },
   "source": [
    "Операции с векторами     \n",
    "\n",
    "![](https://www.distilled.net/uploads/word2vec_chart.jpg)  \n",
    "\n",
    "+ positive - все, что хотим прибавить \n",
    "+ negative - все, что хоти отнять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLeUK5_vbTRc"
   },
   "outputs": [],
   "source": [
    "# сын + женщина = ?\n",
    "model.most_similar(positive=['сын_NOUN', 'женщина_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFaxWC1Rbgcl"
   },
   "outputs": [],
   "source": [
    "# мать - женщина = ?\n",
    "model.most_similar(positive=['мать_NOUN'], negative=['женщина_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5AwZmJTZMW1"
   },
   "outputs": [],
   "source": [
    "# кошка - женщина = ?\n",
    "model.most_similar(positive=['кошка_NOUN'], negative=['женщина_NOUN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-XcAYek3fwaA"
   },
   "outputs": [],
   "source": [
    "# россия - москва + париж = ?\n",
    "model.most_similar(positive=['россия_NOUN', 'париж_NOUN'], negative=['москва_NOUN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz0hLAS4b5i0"
   },
   "source": [
    "Обучить свою модель "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "87ORXZHvmADu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "-2qcRtvTqWhd",
    "outputId": "fb539e02-337b-49a3-b50f-29c1654c2f74"
   },
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9FE6S1bhI2U"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = newsgroups.data\n",
    "df['target'] = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "g7aYMG4XsUEc",
    "outputId": "963942fc-f02d-422f-9023-e5425eff8e7f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenized_documents = [word_tokenize(text.lower()) for text in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0H8Zn1pcZfk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "It_X3LB0uSAe"
   },
   "source": [
    "Обучаем модель       \n",
    "Подробно про параметры модели в [документации](https://radimrehurek.com/gensim/models/word2vec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Fdg9XjC4cHtQ",
    "outputId": "fbe11907-38ec-403a-c6e5-e698461aad2a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "my_model = Word2Vec(sentences=tokenized_documents, # список списков токенов для каждого документа\n",
    "                    min_count=10, # игнорировать слова которые встречаются реже\n",
    "                    sg=0, # какой алгоритм применить 0 - cbow, 1 - skipgram\n",
    "                    workers=4, \n",
    "                    size=150) # длина вектора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BkjUKiDXwiJn"
   },
   "source": [
    "Сохраняем модель:\n",
    "+ Если не планируем дообучать, то можно сохранить только словарь векторов - объект `KeyedVectors`, хранится в атрибуте ***model.wv***\n",
    "+ Если хотим дообучить, то сохраняем целиком (займет больше места)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "ONCRpnF5tPCQ",
    "outputId": "c1d665ea-b407-4e1f-990e-489d2111fe06",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# только векторы\n",
    "vectors = my_model.wv\n",
    "vectors.save('my_vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всю модель\n",
    "my_model.save('my_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем назад"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vectors = KeyedVectors.load('my_vectors.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_vectors.get_vector('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vectors.mhttps://i0.wp.com/yaronvazana.com/wp-content/uploads/2018/09/average-vectors.png?w=698ost_similar('nice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Полученные векторы можно использовать в качестве признаков для обучения.   \n",
    "+ Но в каждом документе разное количество слов. Необходимо привести все документы к одной размерности, чтобы получить матрицу объектов-признаков. \n",
    "+ Самый популярный способ - поэлементное усреднение векторов всех слов в документе. \n",
    "+ Итоговый результат - матрица ***(Кол-во объектов х Размерность вектора)***\n",
    "\n",
    "![](https://i0.wp.com/yaronvazana.com/wp-content/uploads/2018/09/average-vectors.png?w=698)\n",
    "\n",
    "Что еще делают:\n",
    "+ Поэлементный минимум\n",
    "+ Поэлементный максимум\n",
    "+ Конкатенация всех векторов + подложка из 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKen9Jc-qhN_"
   },
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "np.random.seed(123)\n",
    "df_train, df_test = train_test_split(df, train_size=0.5, test_size=0.3, stratify=df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vectors.get_vector('hhhhh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить вектор документа - усреднить векторы слов\n",
    "def get_doc_vector(document):\n",
    "    tokens = word_tokenize(document.lower())\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vector = my_vectors.get_vector(token)\n",
    "            vectors.append(vector)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_doc_vector(df_train.text[10]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ifaWYaBcIpW"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = np.matrix([get_doc_vector(document) for document in df_train.text])\n",
    "X_test = np.matrix([get_doc_vector(document) for document in df_test.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_jobs=-1, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, df_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(df_test.target, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09.06natural_language2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
